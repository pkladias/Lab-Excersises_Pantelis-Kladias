{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edcb4574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\pklad\\anaconda3\\lib\\site-packages (4.8.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: idna in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\pklad\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "705586bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9fa947",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Service(\"C:\\Program Files (x86)\\chromedriver.exe\") \n",
    "driver = webdriver.Chrome(service=PATH)\n",
    "\n",
    "driver.get(\"https://www.binghamton-ny.gov/home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "210c567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Government = driver.find_element(By.XPATH, \"//*[@id='dropdownrootitem3']/a\")\n",
    "Government.click()\n",
    "Department = driver.find_element(By.XPATH, \"//*[@id='dropdownrootitem3']/div/div/ul[1]/li/a\")\n",
    "Department.click()\n",
    "\n",
    "try:\n",
    "    Personel_Civil_Service = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"//*[@id='widget_4_33_127']/ul/li[16]/a\"))\n",
    "    )\n",
    "  \n",
    "    Personel_Civil_Service.click()\n",
    "    \n",
    "   \n",
    "    Employment_Page= WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//*[@id='leftNav_1038_0_145']/ul/li/ul/li[14]/ul/li/a\"))\n",
    "    )\n",
    "    Employment_Page.click()\n",
    "    \n",
    "    \n",
    "    webtable_df = pd.read_html(driver.find_element(By.XPATH, \"//*[@id='ColumnUserControl4']/div[2]/table\").get_attribute('outerHTML'))[0]\n",
    "    webtable_df.to_csv('Job Openings.csv')\n",
    "    # tried using for loop and getting each element by class name but it would not work so I looked up alternative way online\n",
    "    \n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c90cd7d",
   "metadata": {},
   "source": [
    "## Sources Used\n",
    "\n",
    "https://anaasher.medium.com/web-scraping-how-to-use-python-selenium-to-extract-data-from-html-table-7e6e3bcaebd6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f96a91b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
